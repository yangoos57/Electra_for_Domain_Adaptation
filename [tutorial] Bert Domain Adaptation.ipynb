{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"drV3Sl6HpHWc","executionInfo":{"status":"ok","timestamp":1671626009570,"user_tz":-540,"elapsed":2254,"user":{"displayName":"yangwoo lee","userId":"07893621939305411702"}},"outputId":"9969ac35-bf4d-4719-80f6-47d33e4a7436"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OhFIfvU3pI4X","executionInfo":{"status":"ok","timestamp":1671626014171,"user_tz":-540,"elapsed":4603,"user":{"displayName":"yangwoo lee","userId":"07893621939305411702"}},"outputId":"e01456ed-b49c-41a2-9226-6efe4975c1c7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.11)\n"]}]},{"cell_type":"code","source":["pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E_mnAssdpcZM","executionInfo":{"status":"ok","timestamp":1671626018372,"user_tz":-540,"elapsed":4224,"user":{"displayName":"yangwoo lee","userId":"07893621939305411702"}},"outputId":"9e0f4279-794b-4ce6-fca4-3baf7217313f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.8.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.1.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ckTzhz0LpK5x","executionInfo":{"status":"ok","timestamp":1671626019267,"user_tz":-540,"elapsed":901,"user":{"displayName":"yangwoo lee","userId":"07893621939305411702"}},"outputId":"cc4ed693-6511-4ae2-980e-88a090d20cc6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Dec 21 12:33:38 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   69C    P0    31W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g7wMZn9OpEuP","executionInfo":{"status":"ok","timestamp":1671626027321,"user_tz":-540,"elapsed":8057,"user":{"displayName":"yangwoo lee","userId":"07893621939305411702"}},"outputId":"30fe6fa8-c8b8-41c3-a3dd-37bb03dfbe9b"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["from transformers import BertForMaskedLM, BertTokenizer,Trainer,DataCollatorForLanguageModeling\n","\n","\n","tokenizer = BertTokenizer.from_pretrained('beomi/kcbert-base')\n","model = BertForMaskedLM.from_pretrained('beomi/kcbert-base')"]},{"cell_type":"code","source":["import os\n","!pwd\n","os.chdir('/content/drive/MyDrive/Colab Notebooks/Bert_For_Fine_Tuning')\n","!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1H_pBQP-pTO9","executionInfo":{"status":"ok","timestamp":1671626027778,"user_tz":-540,"elapsed":467,"user":{"displayName":"yangwoo lee","userId":"07893621939305411702"}},"outputId":"715bffa0-b03c-46e9-802a-7d6855aa6a1b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/drive/MyDrive/Colab Notebooks/Bert_For_Fine_Tuning\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172,"referenced_widgets":["5f0768e527b046038ef9061f249bfb33","2fd5e9e97d2c4dc3be8b41f7f91a568a","b2b78f1ef5774b308ba8ae14eae5b9f3","43ab320d028e4f78b351aa930e1d4aee","affa15ea4a8944b6b5d8d00452d9ddfe","69a706c3205945ac8a34f6d71db2bc10","04da0b29768743f4b0e7bdda2c10927a","7b66b2873d084af9a30ed2522be7a98b","16707d2247bb494292a39943faba9f0d","1ee776c04df84acd983774ca92ea7683","b1af4508031641258a60d928a94a7cf6","671412ccde39429ca85edbd1050c0f8e","177fcd601f404918a48f984c638fdaa0","128ac2f18c354e188c922a735d8fca44","4e50abfdd3dd47cdb0a4e29781d17933","df8cff10669845d9a95101dfcc4b4981","8f9cb923faa740748b1d99e8d5ea0af1","a02bf852a87440b6acc6df01f35eb713","a40658a709b64564875573a1dcf50b7f","8ea0e5a200ce48d2bc9867d04dadfc82","f71b2b45090740feb28d968627fc4858","8d866dfc7d914d3988175f42ecc1804d"]},"id":"kVd_f51opEuQ","executionInfo":{"status":"ok","timestamp":1671626028066,"user_tz":-540,"elapsed":294,"user":{"displayName":"yangwoo lee","userId":"07893621939305411702"}},"outputId":"eb410705-b53e-4e23-a476-37873e5595d8"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Using custom data configuration default-9028144b79c131ae\n","WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-9028144b79c131ae/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f0768e527b046038ef9061f249bfb33"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Using custom data configuration default-ee34893d563a1ad5\n","WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-ee34893d563a1ad5/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"671412ccde39429ca85edbd1050c0f8e"}},"metadata":{}}],"source":["from datasets import load_dataset\n","\n","train = load_dataset('csv',data_files='data/book_train_128.csv')\n","validation = load_dataset('csv',data_files='data/book_validation_128.csv')"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tqIWBz3FpEuQ","executionInfo":{"status":"ok","timestamp":1671626029453,"user_tz":-540,"elapsed":1389,"user":{"displayName":"yangwoo lee","userId":"07893621939305411702"}},"outputId":"e8c6cfee-dadd-4ec2-abd6-8d7de0c49edc"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-9028144b79c131ae/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-b6497e8e5d779f8a.arrow\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-ee34893d563a1ad5/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-cf79eae49b964aec.arrow\n"]}],"source":["def tokenize_function(examples):\n","    return tokenizer(examples['sen'], max_length=128, padding=True, truncation=True)\n","\n","train_data_set = train['train'].map(tokenize_function,batch_size=True)\n","validation_data_set = validation['train'].map(tokenize_function,batch_size=True)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"7OKLcBTOpEuR","executionInfo":{"status":"ok","timestamp":1671632029593,"user_tz":-540,"elapsed":6000144,"user":{"displayName":"yangwoo lee","userId":"07893621939305411702"}},"outputId":"8a1c7150-7ba0-4e81-9834-1ade78d065e1"},"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: Unnamed: 0, sen. If Unnamed: 0, sen are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 175900\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 5498\n","  Number of trainable parameters = 108950064\n"]},{"output_type":"stream","name":"stdout","text":["\n","0번째 epoch 진행 중 ------- 0번째 step 결과\n","input 문장 : 장 수학 기호 수식에 [MASK] 쓰이는 그리스 알 [MASK]벳을 읽고 [MASK] 법을 배 [MASK]니다\n","output 문장 : 장르 기호 수식에 [##서] 쓰이는군요 알 [##파]벳을 읽고 [배우는] 법을 배 [##웁]니다\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5498' max='5498' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5498/5498 1:39:56, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>3.163900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>2.946900</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>2.840500</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>2.829800</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>2.730200</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>2.740500</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>2.701600</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>2.638800</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>2.680800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.598500</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>2.620700</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>2.576200</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>2.561900</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>2.545900</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>2.533100</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>2.469600</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>2.500100</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>2.466100</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>2.483000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>2.456500</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>2.463400</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>2.449400</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>2.432700</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>2.384800</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>2.365000</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>2.397400</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>2.413800</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>2.328300</td>\n","    </tr>\n","    <tr>\n","      <td>2900</td>\n","      <td>2.323100</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>2.337000</td>\n","    </tr>\n","    <tr>\n","      <td>3100</td>\n","      <td>2.290400</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>2.308200</td>\n","    </tr>\n","    <tr>\n","      <td>3300</td>\n","      <td>2.295600</td>\n","    </tr>\n","    <tr>\n","      <td>3400</td>\n","      <td>2.266700</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>2.273900</td>\n","    </tr>\n","    <tr>\n","      <td>3600</td>\n","      <td>2.303000</td>\n","    </tr>\n","    <tr>\n","      <td>3700</td>\n","      <td>2.291700</td>\n","    </tr>\n","    <tr>\n","      <td>3800</td>\n","      <td>2.249700</td>\n","    </tr>\n","    <tr>\n","      <td>3900</td>\n","      <td>2.242200</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>2.241900</td>\n","    </tr>\n","    <tr>\n","      <td>4100</td>\n","      <td>2.235400</td>\n","    </tr>\n","    <tr>\n","      <td>4200</td>\n","      <td>2.201400</td>\n","    </tr>\n","    <tr>\n","      <td>4300</td>\n","      <td>2.199800</td>\n","    </tr>\n","    <tr>\n","      <td>4400</td>\n","      <td>2.197900</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>2.233000</td>\n","    </tr>\n","    <tr>\n","      <td>4600</td>\n","      <td>2.218000</td>\n","    </tr>\n","    <tr>\n","      <td>4700</td>\n","      <td>2.244200</td>\n","    </tr>\n","    <tr>\n","      <td>4800</td>\n","      <td>2.211800</td>\n","    </tr>\n","    <tr>\n","      <td>4900</td>\n","      <td>2.181900</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>2.200800</td>\n","    </tr>\n","    <tr>\n","      <td>5100</td>\n","      <td>2.226400</td>\n","    </tr>\n","    <tr>\n","      <td>5200</td>\n","      <td>2.183400</td>\n","    </tr>\n","    <tr>\n","      <td>5300</td>\n","      <td>2.174700</td>\n","    </tr>\n","    <tr>\n","      <td>5400</td>\n","      <td>2.202700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","0번째 epoch 진행 중 ------- 100번째 step 결과\n","input 문장 : 물론 [MASK] [MASK] [MASK] 이루어졌고 페 [MASK] [MASK] 어떻게 구성되었 [MASK] 보여주는 것들도 부분부분 있어서 [MASK]지\n","output 문장 : 물론 [페] [##적인] [어떻게] 이루어졌고 페 [##이지] [##이] 어떻게 구성되었 [##는지] 보여주는 것들도 부분부분 있어서 [좋았]지\n","\n","0번째 epoch 진행 중 ------- 200번째 step 결과\n","input 문장 : 이를테 [MASK] 신체화 떙 embody 라는 동사와 신체화 embodiment 라는 [MASK]사는 인간이 무언 [MASK] 우리의 [MASK]화 한다는 [MASK]\n","output 문장 : 이를테 [##면] 신체화와 embody 라는 동사와 신체화 embodiment 라는 [동]사는 인간이 무언 [##가] 우리의 [시각]화 한다는 [것이다]\n","\n","0번째 epoch 진행 중 ------- 300번째 step 결과\n","input 문장 : 윈도우 을 기반으로 기본적으로 사용하는 파 [MASK]과 폴더 그리고 [MASK] 사용 방법에 대해 알려줍니다\n","output 문장 : 윈도우 를 기반으로 기본적으로 사용하는 파 [##일]과 폴더 그리고 [그] 사용 방법에 대해 알려줍니다\n","\n","0번째 epoch 진행 중 ------- 400번째 step 결과\n","input 문장 : 핵심만 [MASK] [MASK] 골라 수험생들의 시간을 아껴드리 [MASK]\n","output 문장 : 핵심만 [핵심] [##하게] 골라 수험생들의 시간을 아껴드리 [##겠습니다]\n"]},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to test_trainer/checkpoint-500\n","Configuration saved in test_trainer/checkpoint-500/config.json\n","Model weights saved in test_trainer/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in test_trainer/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in test_trainer/checkpoint-500/special_tokens_map.json\n"]},{"output_type":"stream","name":"stdout","text":["\n","0번째 epoch 진행 중 ------- 500번째 step 결과\n","input 문장 : 프로그래밍 [MASK]토리얼을 알고 있는 사람이라도 다시 한번 읽어보면 [MASK] 모르는 사람에게는 친절한 안내서의 역할을 한다 [MASK]\n","output 문장 : 프로그래밍 [튜]토리얼을 알고 있는 사람이라도 다시 한번 읽어보면 [아무것도] 모르는 사람에게는 친절한 안내서의 역할을 한다 [.]\n","\n","0번째 epoch 진행 중 ------- 600번째 step 결과\n","input 문장 : 이 책을 통해 [MASK]습과 반복연 [MASK]을 하면서 느낀 점은 [MASK] 프로그램은 무작정 하루에 [MASK] 들여 따라 키 자신 [MASK] 방법으로 약간 변 [MASK]해보는 것을 [MASK] 하면 실력이 늘 수 있다는 것이다 .\n","output 문장 : 이 책을 통해 [실]습과 반복연 [##습]을 하면서 느낀 점은 [이] 프로그램은 무작정 하루에 [하나씩] 들여 따라하면서는 [##만의] 방법으로 약간 변 [##환]해보는 것을 [따라] 하면 실력이 늘 수 있다는 것이다 .\n","\n","0번째 epoch 진행 중 ------- 700번째 step 결과\n","input 문장 : [MASK]팝은 섬네일을 어떻게 만들지 씨부려라하는데 99 머리를 쥐어짠다고 한다 .\n","output 문장 : [이]팝은 섬네일을 어떻게 만들지 이해하는데 다시 머리를 쥐어짠다고 한다 .\n","\n","0번째 epoch 진행 중 ------- 800번째 step 결과\n","input 문장 : 이 [MASK] 통해 웹 개발에 필요한 표준 라이브러리와 [MASK]용성 높은 Djang [MASK]를껬해보자\n","output 문장 : 이 [책을] 통해 웹 개발에 필요한 표준 라이브러리와 [실]용성 높은 Djang [언어]를 사용해보자\n","\n","0번째 epoch 진행 중 ------- 900번째 step 결과\n","input 문장 : 처음에는 [MASK] 몰라서 프 [MASK] [MASK]스에 치중을 [MASK] .\n","output 문장 : 처음에는 [잘] 몰라서 프 [##린] [##턴]스에 치중을 [한다] .\n"]},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to test_trainer/checkpoint-1000\n","Configuration saved in test_trainer/checkpoint-1000/config.json\n","Model weights saved in test_trainer/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in test_trainer/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in test_trainer/checkpoint-1000/special_tokens_map.json\n"]},{"output_type":"stream","name":"stdout","text":["\n","0번째 epoch 진행 중 ------- 1000번째 step 결과\n","input 문장 : 오늘날 다양한 분야에서 활동하는 사람들이 공통의 [MASK]로 한 방 에 모여 진정성 있는 [MASK]로 소통 문화를 만들어가는 [MASK] [MASK] 미디어는 오직 클럽하우스라고 해도 과 [MASK] 아니다\n","output 문장 : 오늘날 다양한 분야에서 활동하는 사람들이 공통의 [언어]로 한 방 에 모여 진정성 있는 [세계]로 소통 문화를 만들어가는 [한국] [##과] 미디어는 오직 클럽하우스라고 해도 과 [##언이] 아니다\n","\n","0번째 epoch 진행 중 ------- 1100번째 step 결과\n","input 문장 : 좋은 [MASK] [MASK] 가져오면 된다 .\n","output 문장 : 좋은 [책] [##을] 가져오면 된다 .\n","\n","0번째 epoch 진행 중 ------- 1200번째 step 결과\n","input 문장 : 레 [MASK]런스 북으로도 손 [MASK] 없다\n","output 문장 : 레 [##퍼]런스 외에도 손 [##색이] 없다\n","\n","0번째 epoch 진행 중 ------- 1300번째 step 결과\n","input 문장 : [MASK] [MASK]를 다루고 있는 저도 [MASK]던 부분이 많았고 도움이 되는 부분이 많았습니다 .\n","output 문장 : [이] [용어]를 다루고 있는 저도 [좋았]던 부분이 많았고 도움이 되는 부분이 많았습니다 .\n","\n","0번째 epoch 진행 중 ------- 1400번째 step 결과\n","input 문장 : 이런 [MASK]에서 인간은 자신이 [MASK] 로봇과 별반 쟤는 없다고 봐야 할 것이다\n","output 문장 : 이런 [환경]에서 인간은 자신이 [만든] 로봇과 별반 차이가 없다고 봐야 할 것이다\n"]},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to test_trainer/checkpoint-1500\n","Configuration saved in test_trainer/checkpoint-1500/config.json\n","Model weights saved in test_trainer/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in test_trainer/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in test_trainer/checkpoint-1500/special_tokens_map.json\n"]},{"output_type":"stream","name":"stdout","text":["\n","0번째 epoch 진행 중 ------- 1500번째 step 결과\n","input 문장 : 자바완전정복 [MASK] 이지스 퍼블리싱의 명성에 걸맞게 자바 입문서지는건 꽤 훌륭한 선택이 될 수 있는 책이다 .\n","output 문장 : 자바 완전정복 [##하려면] 이지스퍼블리싱의 명성에 걸맞게 자바 입문서는 꽤 훌륭한 선택이 될 수 있는 책이다 .\n","\n","0번째 epoch 진행 중 ------- 1600번째 step 결과\n","input 문장 : 전문가로 만들어 주는 책이라 생각된다 .\n","output 문장 : 전문가로 만들어 주는 책이라 생각된다 .\n","\n","0번째 epoch 진행 중 ------- 1700번째 step 결과\n","input 문장 : 평균값에 [MASK] 차이가 있는지 흩어진 상태에 정말 [MASK] 무식하고 근거를코로나 판단하는 방법의 하나가 검정입니다 .\n","output 문장 : 평균값에 [어떤] 차이가 있는지 흩어진 상태에 정말 [사용]인지 비 가지고 판단하는 방법의 하나가 검정입니다 .\n","\n","0번째 epoch 진행 중 ------- 1800번째 step 결과\n","input 문장 : 단순히 [MASK] 코드를 수록해놓은 책 이 아니라 다양한 기술 의사결정의 [MASK]점이 되어줄 책입니다\n","output 문장 : 단순히 [웹] 코드를 수록해놓은 책 이 아니라 다양한 기술 의사결정의 [출발]점이 되어줄 책입니다\n","\n","0번째 epoch 진행 중 ------- 1900번째 step 결과\n","input 문장 : 그럼에도 불구하고 미래가 궁금하고 우리의 생활이 빅 [MASK]터로 인해 [MASK] 변화해나가고 [MASK]으로 [MASK] 준비해야하는지에 대한 생각이 있는 사람이라면 꼭 읽어보시길 .\n","output 문장 : 그럼에도 불구하고 미래가 궁금하고 우리의 생활이 빅 [##데이]터로 인해 [어떻게] 변화해나가고 [무엇]으로 [무엇을] 준비해야하는지에 대한 생각이 있는 사람이라면 꼭 읽어보시길 .\n"]},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to test_trainer/checkpoint-2000\n","Configuration saved in test_trainer/checkpoint-2000/config.json\n","Model weights saved in test_trainer/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in test_trainer/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in test_trainer/checkpoint-2000/special_tokens_map.json\n"]},{"output_type":"stream","name":"stdout","text":["\n","0번째 epoch 진행 중 ------- 2000번째 step 결과\n","input 문장 : 회사 신입 개발자들을 위해 사주었는데 [MASK]전공자들을 위한 책이라 도움이 되지는 않네요 .\n","output 문장 : 회사 신입 개발자들을 위해 샀었는데 [비]전공자들을 위한 책이라 도움이 되지는 않네요 .\n","\n","0번째 epoch 진행 중 ------- 2100번째 step 결과\n","input 문장 : 쿠버네 [MASK] [MASK] 대한 소개 [MASK] 개념 오브젝 [MASK] 실제 애플리케이 [MASK] 배포 [MASK]습까지 이 책 [MASK] 각 장 절마다 독자들의 [MASK] 호기심을 [MASK]해 책을 읽으면 읽을수록 점점 더 쿠버네 [MASK] [MASK]의 [MASK]에 빠지 [MASK]속도\n","output 문장 : 쿠버네 [##티] [##스에] 대한 소개 [##와] 개념 오브젝 [##트] 실제 애플리케이 [##션] 배포 [실]습까지 이 책 [##은] 각 장 절마다 독자들의 [뜨거운] 호기심을 [자극]해 책을 읽으면 읽을수록 점점 더 쿠버네 [##이버] [##트]의 [매력]에 빠지 [##기] 것이다\n","\n","0번째 epoch 진행 중 ------- 2200번째 step 결과\n","input 문장 : 이책의 특징 개가 넘는 실습과 트레이닝이 가득하다 일러스트레이터의 기본 [MASK]과 [MASK] 기능 몰라서 쓰지 못했던 숨어 있는 [MASK]을 개가 넘는 실습으로 설명 [MASK]\n","output 문장 : 이책의 특징 개가 넘는 실습과 트레이닝이 가득하다 일러스트레이터의 기본 [기능]과 [핵심] 기능을 쓰지 못했던 숨어 있는 [기능]을 개가 넘는 실습으로 설명 [##한다]\n","\n","0번째 epoch 진행 중 ------- 2300번째 step 결과\n","input 문장 : 이 [MASK]의 [MASK]는 일본 공학교육협회에서 저작상을 수상한 프로그래밍 교육서 [MASK] [MASK]인입니다\n","output 문장 : 이 [책]의 [저자]는 일본 공학교육협회에서 저작상을 수상한 프로그래밍 교육서 [##의] [##서]인입니다\n","\n","0번째 epoch 진행 중 ------- 2400번째 step 결과\n","input 문장 : 내 만두만 먹어야 하는데요 화살표가 떨어지면 게임은 끝 .\n","output 문장 : 내 만두만 먹어야 하는데요 화살표가 떨어지면 게임은 끝 .\n"]},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to test_trainer/checkpoint-2500\n","Configuration saved in test_trainer/checkpoint-2500/config.json\n","Model weights saved in test_trainer/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in test_trainer/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in test_trainer/checkpoint-2500/special_tokens_map.json\n"]},{"output_type":"stream","name":"stdout","text":["\n","0번째 epoch 진행 중 ------- 2500번째 step 결과\n","input 문장 : 마지막으로 [MASK]친마음 [MASK] [MASK]해주는 나의 사랑하는 가족들에게도 감사의 마음을 전한다\n","output 문장 : 마지막으로 [지]친마음 [##을] [전달]해주는 나의 사랑하는 가족들에게도 감사의 마음을 전한다\n","\n","0번째 epoch 진행 중 ------- 2600번째 step 결과\n","input 문장 : [MASK]5년 미국에서 시작된 세계 [MASK] [MASK] 동영상 공유 사이트인 유튜브는 [MASK] 현대인들의 삶에 중요한 부분으로 자리를 잡고 있다 [MASK]\n","output 문장 : [201]5년 미국에서 시작된 세계 [최초] [유튜브] 동영상 공유 사이트인 유튜브는 [이미] 현대인들의 삶에 중요한 부분으로 자리를 잡고 있다 [.]\n","\n","0번째 epoch 진행 중 ------- 2700번째 step 결과\n","input 문장 : 파워블로 [MASK] [MASK] 필자는 블로그 초 [MASK] 일으 [MASK] 도서와 블로그를 통한 마케팅 도서를 집필 연이어 [MASK]셀러가 되었고 2012년 새로운 블로그 생태계와 소셜네트워크서비스 [MASK]NS [MASK] 활성화에 따라 새롭게 [MASK] 블로그 관리 노하우를 공개했다 .\n","output 문장 : 파워블로 [##잉] [##의] 필자는 블로그 초 [##장을] 일으 [##킬] 도서와 블로그를 통한 마케팅 도서를 집필 연이어 [베스트]셀러가 되었고 2012년 새로운 블로그 생태계와 소셜네트워크서비스 [##S]NS [##의] 활성화에 따라 새롭게 [새로운] 블로그 관리 노하우를 공개했다 .\n","\n","1번째 epoch 진행 중 ------- 2800번째 step 결과\n","input 문장 : 배포할 apk파일 서명하기 및 apk파일 [MASK]성한 뒤에 원하는 위치로 파일 옮기 [MASK]제품 특성에 따라 flav향를 만들거나 buil [MASK] [MASK]ype [MASK] de [MASK] [MASK]g나 release말고도 추가로 생성하기안드로이드 라이브러리 프로젝 [MASK] 효율적으로 사용하기 및 소스세트 [MASK] 변경하기빌 [MASK] 프로 [MASK]일 [MASK] P [MASK]u [MASK]in을 사용 [MASK] 위해 DSL 문서 활용하기Espresso를 [MASK] T [MASK]t하기 등이 될 것이다 .\n","output 문장 : 배포할 apk파일 서명하기 및 apk파일 [생]성한 뒤에 원하는 위치로 파일 옮기 [##기]제품 특성에 따라 flavo를 만들거나 buil [##a] [##t]ype [##와] de [##le] [##a]g나 release 외에도 추가로 생성하기안드로이드 라이브러리 프로젝 [##트를] 효율적으로 사용하기 및 소스세트 [##로] 변경하기 빌 [##드] 프로 [##파]일 [및] P [##r]u [##l]in을 사용 [##하기] 위해 DSL 문서 활용하기 Aspresso를 [통한] T [##ar]t하기 등이 될 것이다 .\n","\n","1번째 epoch 진행 중 ------- 2900번째 step 결과\n","input 문장 : 마치 고전 소설 [MASK] 고전 음악 [MASK] 잘 정리된 리듬의 [MASK]화 [MASK] 같멍\n","output 문장 : 마치 고전 소설 [##과] 고전 음악 [##이] 잘 정리된 리듬의 [심]화 [##와] 같았다\n"]},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to test_trainer/checkpoint-3000\n","Configuration saved in test_trainer/checkpoint-3000/config.json\n","Model weights saved in test_trainer/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in test_trainer/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in test_trainer/checkpoint-3000/special_tokens_map.json\n"]},{"output_type":"stream","name":"stdout","text":["\n","1번째 epoch 진행 중 ------- 3000번째 step 결과\n","input 문장 : 중략 가상의 [MASK]는 하인이 되겠지만 우리가 조심하지 않는다면 우리의 주인이 될 [MASK] .\n","output 문장 : 중략 가상의 [컴퓨터]는 하인이 되겠지만 우리가 조심하지 않는다면 우리의 주인이 될 [것이다] .\n","\n","1번째 epoch 진행 중 ------- 3100번째 step 결과\n","input 문장 : 일단 제가 볼 책은 아니고 [MASK] 막 인터넷 [MASK]하실려는 저희 이모부께 선물 [MASK]렸어요 .\n","output 문장 : 일단 제가 볼 책은 아니고 [이제] 막 인터넷 [##을]하실려는 저희 이모부께 선물 [##드]렸어요 .\n","\n","1번째 epoch 진행 중 ------- 3200번째 step 결과\n","input 문장 : 장 역시 장에 이어 [MASK]웨어적인 내용으로 C [MASK]U의 구조에 [MASK] [MASK] 다룬다\n","output 문장 : 장 역시 장에 이어 [하드]웨어적인 내용으로 C [##P]U의 구조에 [대해] [내용을] 다룬다\n","\n","1번째 epoch 진행 중 ------- 3300번째 step 결과\n","input 문장 : 파 [MASK]선을 처음 접하는 프로그램 [MASK]문자를 위해 컴퓨팅 사고를 [MASK]상시키고 컴퓨팅 [MASK]에믿 이해를 원하는 학습자를 위해 구성했다\n","output 문장 : 파 [##이]선을 처음 접하는 프로그램 [입]문자를 위해 컴퓨팅 사고를 [향]상시키고 컴퓨팅 [사고]에 대해 이해를 원하는 학습자를 위해 구성했다\n","\n","1번째 epoch 진행 중 ------- 3400번째 step 결과\n","input 문장 : 그래도 책을 따라 [MASK] 때는 체험 [MASK] 사용하는게 [MASK]거 [MASK] 설치하려는데 [MASK] 노트북이 되지 않네요 힘내시고 . .\n","output 문장 : 그래도 책을 따라 [##할] 때는 체험 [##용으로] 사용하는게 [번]거 [##워서] 설치하려는데 [좋은] 책이 되지 않네요 . . .\n"]},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to test_trainer/checkpoint-3500\n","Configuration saved in test_trainer/checkpoint-3500/config.json\n","Model weights saved in test_trainer/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in test_trainer/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in test_trainer/checkpoint-3500/special_tokens_map.json\n"]},{"output_type":"stream","name":"stdout","text":["\n","1번째 epoch 진행 중 ------- 3500번째 step 결과\n","input 문장 : 좋은 책 잘 읽겠습니다 .\n","output 문장 : 좋은 책 잘 읽겠습니다 .\n","\n","1번째 epoch 진행 중 ------- 3600번째 step 결과\n","input 문장 : 네 번째 발걸음 [MASK] 속하는 장에서는 네트워킹 자동 [MASK] 기술에 필수인 기본 리 [MASK]스 사용법을 배워 중요 네트워크 서비스인 FTP SFTP TFTP와 N [MASK]P [MASK] [MASK] CentOS\n","output 문장 : 네 번째 발걸음 [##에] 속하는 장에서는 네트워킹 자동 [##화] 기술에 필수인 기본 리 [##눅]스 사용법을 배워보고 네트워크 서비스인 FTP SFTP TFTP와 N [##L]P [C] [##P] CentOS\n","\n","1번째 epoch 진행 중 ------- 3700번째 step 결과\n","input 문장 : 책 제목에 코딩이 들어가기만 하면 눈길이 가더라구요 .\n","output 문장 : 책 제목에 코딩이 들어가기만 하면 눈길이 가더라구요 .\n","\n","1번째 epoch 진행 중 ------- 3800번째 step 결과\n","input 문장 : zip 형식의 [MASK]축을 풀어야 한다\n","output 문장 : zip 형식의 [단]축을 풀어야 한다\n","\n","1번째 epoch 진행 중 ------- 3900번째 step 결과\n","input 문장 : 다만 ES5 이후의 내용을 다루지는 않고있습니다 .\n","output 문장 : 다만 ES5 이후의 내용을 다루지는 않고있습니다 .\n"]},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to test_trainer/checkpoint-4000\n","Configuration saved in test_trainer/checkpoint-4000/config.json\n","Model weights saved in test_trainer/checkpoint-4000/pytorch_model.bin\n","tokenizer config file saved in test_trainer/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in test_trainer/checkpoint-4000/special_tokens_map.json\n"]},{"output_type":"stream","name":"stdout","text":["\n","1번째 epoch 진행 중 ------- 4000번째 step 결과\n","input 문장 : 시중에 넘쳐나는 파이썬 책 떼 있지만 이 책 처럼 쉽 [MASK] 친절하게 [MASK]되어 있는 책은 아직 본적이 [MASK] .\n","output 문장 : 시중에 넘쳐나는 파이썬 책들이 있지만 이 책 처럼 쉽 [##고] 친절하게 [설명]되어 있는 책은 아직 본적이 [없다] .\n","\n","1번째 epoch 진행 중 ------- 4100번째 step 결과\n","input 문장 : 초등 컴퓨 [MASK] 교사협회 [MASK]도 [MASK]라고휀\n","output 문장 : 초등 컴퓨 [##팅] 교사협회 [에서]도 [마찬가지]라고 합니다\n","\n","1번째 epoch 진행 중 ------- 4200번째 step 결과\n","input 문장 : 다음 기회에는 좀더 다양한 유튜브 활용 기회가 제공 [MASK] [MASK] 바램 그리고 [MASK] 인스타그램은 아직 한 번도 접해보지 못한 부분이여서 가장 낯 [MASK]었다 .\n","output 문장 : 다음 기회에는 좀더 다양한 유튜브 활용 기회가 제공 [##되어] [하는] 바램 그리고 [유튜브] 인스타그램은 아직 한 번도 접해보지 못한 부분이여서 가장 낯 [##설]었다 .\n","\n","1번째 epoch 진행 중 ------- 4300번째 step 결과\n","input 문장 : 후반부에서 [MASK] 머신러 [MASK] 생명주기를 따라가며 [MASK] 도구와 고려할 사항을 알려주고 최종적으로 쿠버네 [MASK]스에 마이크로서 [MASK]로 배포 [MASK] 과정을 단계별로 친절하게 안내한다\n","output 문장 : 후반부에서 [##는] 머신러 [##닝] 생명주기를 따라가며 [해당] 도구와 고려할 사항을 알려주고 최종적으로 쿠버네 [##티]스에 마이크로서 [##비스]로 배포 [##하는] 과정을 단계별로 친절하게 안내한다\n","\n","1번째 epoch 진행 중 ------- 4400번째 step 결과\n","input 문장 : 같은 내용 반복 않는 부분이 너무 많음 .\n","output 문장 : 같은 내용 못지되는 부분이 너무 많음 .\n"]},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to test_trainer/checkpoint-4500\n","Configuration saved in test_trainer/checkpoint-4500/config.json\n","Model weights saved in test_trainer/checkpoint-4500/pytorch_model.bin\n","tokenizer config file saved in test_trainer/checkpoint-4500/tokenizer_config.json\n","Special tokens file saved in test_trainer/checkpoint-4500/special_tokens_map.json\n"]},{"output_type":"stream","name":"stdout","text":["\n","1번째 epoch 진행 중 ------- 4500번째 step 결과\n","input 문장 : 아마존과 달리 칭찬 일색으로만 도배하는 우리나라의 책 Re [MASK]iew는 도대체 어떻게 믿을 수 있나 모르겠다 .\n","output 문장 : 아마존과 달리 칭찬 일색으로만 도배하는 이 책 Re [##v]iew는 도대체 어떻게 믿을 수 있나 모르겠다 .\n","\n","1번째 epoch 진행 중 ------- 4600번째 step 결과\n","input 문장 : 책에서는 [MASK] 딥 [MASK]닝은 머신 러닝의 많은 기법 중 하나이다 .\n","output 문장 : 책에서는 [말하는] 딥 [##러]닝은 머신 러닝의 많은 기법 중 하나이다 .\n","\n","1번째 epoch 진행 중 ------- 4700번째 step 결과\n","input 문장 : 분할 정복 동적 프로 [MASK]밍 탐욕 [MASK] [MASK] 등 [MASK] [MASK] 문제 해결 전략 [MASK] 학습합니다\n","output 문장 : 분할 정복 동적 프로 [##그래]밍과 [##의] [방법] 등 [동] [##적인] 문제 해결 전략 [##을] 학습합니다\n","\n","1번째 epoch 진행 중 ------- 4800번째 step 결과\n","input 문장 : 본 [MASK]개정 판은 [MASK]킷런 learn 업데이 [MASK]에 따라 전반적으로 내용을 갱신한 원서 쇄를 기반 [MASK] 합니다\n","output 문장 : 본 [문]개정 판은 [사이]킷런 learn 업데이 [##트]에 따라 전반적으로 내용을 갱신한 원서 코드를 기반 [##으로] 합니다\n","\n","1번째 epoch 진행 중 ------- 4900번째 step 결과\n","input 문장 : 엔 [MASK]어의 저작은 대 [MASK] 당대의 첨단 결과상만 집중 조명하기에 현황을 [MASK]기에는 좋아도 응용 [MASK] 유효기간에 한계가 뚜렷한 지식이라는 약점이 있습니다 .\n","output 문장 : 엔 [##지니]어의 저작은 대 [##략] 당대의 첨단 결과상만 집중 조명하기에 현황을 [따라가]기에는 좋아도 응용 [##은] 유효기간에 한계가 뚜렷한 지식이라는 약점이 있습니다 .\n"]},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to test_trainer/checkpoint-5000\n","Configuration saved in test_trainer/checkpoint-5000/config.json\n","Model weights saved in test_trainer/checkpoint-5000/pytorch_model.bin\n","tokenizer config file saved in test_trainer/checkpoint-5000/tokenizer_config.json\n","Special tokens file saved in test_trainer/checkpoint-5000/special_tokens_map.json\n"]},{"output_type":"stream","name":"stdout","text":["\n","1번째 epoch 진행 중 ------- 5000번째 step 결과\n","input 문장 : [MASK]의 풍부한 실무 경험에서 나온 [MASK] 실전용 쿼리를 제공합니다\n","output 문장 : [저자]의 풍부한 실무 경험에서 나온 [다양한] 실용 쿼리를 제공합니다\n","\n","1번째 epoch 진행 중 ------- 5100번째 step 결과\n","input 문장 : 전문가가 아닌 [MASK] 머 [MASK]러닝을 이해할 수 있도록 지도 학습 두명 비지도 학습에 해당하는 [MASK] [MASK]리즘을 설명 [MASK]\n","output 문장 : 전문가가 아닌 [사람이] 머 [##신]러닝을 이해할 수 있도록 지도 학습과 비지도 학습에 해당하는 [기초] [알고]리즘을 설명 [##한다]\n","\n","1번째 epoch 진행 중 ------- 5200번째 step 결과\n","input 문장 : 이러한 유 [MASK] 동작 [MASK] 중앙집중형 [MASK]러를 통해 미리 프로그래밍되어 있거나 [MASK] 각 장비 [MASK] 특정한 트래픽을 [MASK]했을 때 [MASK] 동작을 [MASK]할지를 [MASK]러에 물을 수도 있다\n","output 문장 : 이러한 유 [##형으로] 동작 [##은] 초집중형 [컬]러를 통해 미리 프로그래밍되어 있거나 [혹은] 각 장비 [##에] 특정한 트래픽을 [사용]했을 때 [어떤] 동작을 [해야]할지를 [에]러에 물을 수도 있다\n","\n","1번째 epoch 진행 중 ------- 5300번째 step 결과\n","input 문장 : 그 시절 엔지니어링 팀에서 년 동안 우리 팀이 일궈낸 것들은 여전히 [MASK] 커 [MASK]에서 가장 빛나는 부분 [MASK] 하나입니다\n","output 문장 : 그 시절 엔지니어링 팀에서 년 동안 우리 팀이 일궈낸 것들은 여전히 [이] 커 [##널]에서 가장 빛나는 부분 [중] 하나입니다\n","\n","1번째 epoch 진행 중 ------- 5400번째 step 결과\n","input 문장 : 아마존 공인 솔루션스 아키텍트 어소시에이트 자격을 취득하기 위한 [MASK]AA묏 수험서로 출 [MASK]되는 모든 영역에 대한 상세한 설명과 기출 문제 정답 해설을 제공한다\n","output 문장 : 아마존 공인 솔루션스 아키텍트 어소시에이트 자격을 취득하기 위한 [C]AA의 수험서로 출 [##제]되는 모든 영역에 대한 상세한 설명과 기출 문제 정답 해설을 제공한다\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=5498, training_loss=2.4147679067690095, metrics={'train_runtime': 5998.0935, 'train_samples_per_second': 58.652, 'train_steps_per_second': 0.917, 'total_flos': 1.5261062870687616e+16, 'train_loss': 2.4147679067690095, 'epoch': 2.0})"]},"metadata":{},"execution_count":9}],"source":["from transformers import TrainingArguments, TrainerCallback\n","\n","### Training Arguments\n","device = 'cuda'\n","\n","training_args = TrainingArguments(\n","    output_dir=\"test_trainer\",\n","    per_device_eval_batch_size=64,\n","    per_device_train_batch_size=64,\n","    logging_steps=100,\n","    num_train_epochs=2,\n","    evaluation_strategy='epoch'\n",")\n","\n","data_collator_BERT = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, mlm=True, mlm_probability=0.15, return_tensors=\"pt\"\n",")\n","\n","\n","class myCallback(TrainerCallback):\n","    \"\"\"\n","    A bare :class:`~transformers.TrainerCallback` that just prints the logs.\n","    \"\"\"\n","\n","    def on_step_begin(self, args, state, control, logs=None, **kwargs):\n","\n","        # 함수 이름.. 언제 시작할지\n","        # log는 설정할 때마다\n","        # arg,state,control은 참고할 수 있는 attribute의 경우임.\n","        # 근데 내가 필요한건 input\n","        if state.global_step % args.logging_steps == 0:\n","            print(\"\")\n","            print(\n","                f\"{int(state.epoch)}번째 epoch 진행 중 ------- {state.global_step}번째 step 결과\"\n","            )\n","\n","\n","class customtrainer(Trainer):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","\n","    ############# 내용 추가\n","    def step_check(self):\n","        # state는 현 상태를 담는 attribute임.\n","        return self.state.global_step\n","\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        \"\"\"\n","        How the loss is computed by Trainer. By default, all models return the loss in the first element.\n","\n","        Subclass and override for custom behavior.\n","        \"\"\"\n","        if self.label_smoother is not None and \"labels\" in inputs:\n","            labels = inputs.pop(\"labels\")\n","        else:\n","            labels = None\n","        outputs = model(**inputs)\n","        # Save past state if it exists\n","        # TODO: this needs to be fixed and made cleaner later.\n","        if self.args.past_index >= 0:\n","            self._past = outputs[self.args.past_index]\n","\n","        if labels is not None:\n","            loss = self.label_smoother(outputs, labels)\n","        else:\n","            # We don't use .loss here since the model may return tuples instead of ModelOutput.\n","            loss = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n","\n","        ############# 내용 추가\n","        if self.step_check() % self.args.logging_steps == 0:\n","            # step_check = 현 step 파악\n","            # args.logging_steps = argument에서 지정한 step 불러오가\n","\n","            # batch 중 0 번째 위치한 문장 선택\n","            num = 1\n","            input_id = inputs.input_ids[num].reshape(-1).data.tolist()\n","            output_id = outputs.logits[num].argmax(dim=-1).reshape(-1).data.tolist()\n","            attention_mask = inputs.attention_mask[num]\n","\n","            # mask가 위치한 idx 추출하기\n","            mask_idx = (inputs.input_ids[num] == 4).nonzero().data.reshape(-1).tolist()\n","\n","            # padding 제거\n","            input_id_without_pad = [\n","                input_id[i] for i in range(len(input_id)) if attention_mask[i]\n","            ]\n","            output_id_without_pad = [\n","                output_id[i] for i in range(len(output_id)) if attention_mask[i]\n","            ]\n","\n","            # id to token\n","            # [1:-1] [CLS,SEP] 제거\n","            inputs_tokens = self.tokenizer.convert_ids_to_tokens(input_id_without_pad)[\n","                1:-1\n","            ]\n","            outputs_tokens = self.tokenizer.convert_ids_to_tokens(\n","                output_id_without_pad\n","            )[1:-1]\n","\n","            # output mask 부분 표시하기\n","            for i in mask_idx:\n","                # [CLS,SEP 위치 조정]\n","                outputs_tokens[i - 1] = \"[\" + outputs_tokens[i - 1] + \"]\"\n","\n","            inputs_sen = self.tokenizer.convert_tokens_to_string(inputs_tokens)\n","            outputs_sen = self.tokenizer.convert_tokens_to_string(outputs_tokens)\n","\n","            print(f\"input 문장 : {''.join(inputs_sen)}\")\n","            print(f\"output 문장 : {''.join(outputs_sen)}\")\n","\n","        return (loss, outputs) if return_outputs else loss\n","\n","\n","trainer = customtrainer(\n","    model=model.to(device),\n","    train_dataset=train_data_set,\n","    eval_dataset=validation_data_set,\n","    data_collator=data_collator_BERT,\n","    args=training_args,\n","    tokenizer=tokenizer,\n","    callbacks=[myCallback],\n",")\n","\n","trainer.train()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"b2097164ba635ebffc0e3795dc845ae25b57eedf0c1eb5773ded6aee9fc1b279"}},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"5f0768e527b046038ef9061f249bfb33":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2fd5e9e97d2c4dc3be8b41f7f91a568a","IPY_MODEL_b2b78f1ef5774b308ba8ae14eae5b9f3","IPY_MODEL_43ab320d028e4f78b351aa930e1d4aee"],"layout":"IPY_MODEL_affa15ea4a8944b6b5d8d00452d9ddfe"}},"2fd5e9e97d2c4dc3be8b41f7f91a568a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69a706c3205945ac8a34f6d71db2bc10","placeholder":"​","style":"IPY_MODEL_04da0b29768743f4b0e7bdda2c10927a","value":"100%"}},"b2b78f1ef5774b308ba8ae14eae5b9f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b66b2873d084af9a30ed2522be7a98b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_16707d2247bb494292a39943faba9f0d","value":1}},"43ab320d028e4f78b351aa930e1d4aee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ee776c04df84acd983774ca92ea7683","placeholder":"​","style":"IPY_MODEL_b1af4508031641258a60d928a94a7cf6","value":" 1/1 [00:00&lt;00:00, 14.51it/s]"}},"affa15ea4a8944b6b5d8d00452d9ddfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69a706c3205945ac8a34f6d71db2bc10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04da0b29768743f4b0e7bdda2c10927a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b66b2873d084af9a30ed2522be7a98b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16707d2247bb494292a39943faba9f0d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ee776c04df84acd983774ca92ea7683":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1af4508031641258a60d928a94a7cf6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"671412ccde39429ca85edbd1050c0f8e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_177fcd601f404918a48f984c638fdaa0","IPY_MODEL_128ac2f18c354e188c922a735d8fca44","IPY_MODEL_4e50abfdd3dd47cdb0a4e29781d17933"],"layout":"IPY_MODEL_df8cff10669845d9a95101dfcc4b4981"}},"177fcd601f404918a48f984c638fdaa0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f9cb923faa740748b1d99e8d5ea0af1","placeholder":"​","style":"IPY_MODEL_a02bf852a87440b6acc6df01f35eb713","value":"100%"}},"128ac2f18c354e188c922a735d8fca44":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a40658a709b64564875573a1dcf50b7f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8ea0e5a200ce48d2bc9867d04dadfc82","value":1}},"4e50abfdd3dd47cdb0a4e29781d17933":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f71b2b45090740feb28d968627fc4858","placeholder":"​","style":"IPY_MODEL_8d866dfc7d914d3988175f42ecc1804d","value":" 1/1 [00:00&lt;00:00, 15.21it/s]"}},"df8cff10669845d9a95101dfcc4b4981":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f9cb923faa740748b1d99e8d5ea0af1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a02bf852a87440b6acc6df01f35eb713":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a40658a709b64564875573a1dcf50b7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ea0e5a200ce48d2bc9867d04dadfc82":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f71b2b45090740feb28d968627fc4858":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d866dfc7d914d3988175f42ecc1804d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}